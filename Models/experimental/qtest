create model iam

# LOAD DATABASES

# ## LETTER FEATURE REPRESENTATION
create dataframe_for_reps features_db
features_db load Databases/letter_features_no_blank.eNd

# ## ORTHOGRAPHY, PHONOLOGY, FREQUENCIES
create dataframe_for_reps vocab
vocab load Databases/Vocab_files/ia.eNd
#vocab load Databases/Vocab_files/clam.eNd
#vocab load Databases/Vocab_files/iaBLP.eNd
#vocab load Databases/Vocab_files/ia_AoA1.eNd


# LEXICAL ROUTE LAYERS

# ## FEATURE LAYER
create representation feat_rep
feat_rep type blocked_representation
feat_rep set_element (features_db column_rep features)
feat_rep number 4
create iac_layer feature_level
feature_level represent feat_rep
iam define_input orthographic (vocab column_rep Word string_representation) feature_level

#create pattern _mask
#_mask set feat_rep 1P/0 2P/0 3P/0 4A/0 5P/0 6P/0  7A/0 8A/0 9P/0 10P/0 11A/0 12P/0 13P/0 14P/0 1P/1 2P/1 3P/1 4A/1 5P/1 6P/1 7A/1 8A/1 9P/1 10P/1 11A/1 12P/1 13P/1 14P/1 1P/2 2P/2 3P/2 4A/2 5P/2 6P/2 7A/2 8A/2 9P/2 10P/2 11A/2 12P/2 13P/2 14P/2 1P/3 2P/3 3P/3 4A/3 5P/3 6P/3 7A/3 8A/3 9P/3 10P/3 11A/3 12P/3 13P/3 14P/3

# ## LETTER LAYER
create representation letter_rep
letter_rep type blocked_representation
letter_rep set_element (features_db column_rep letter)
letter_rep number 4

create iac_layer letter_level
letter_level represent letter_rep

# ## ORTHORAPHIC LEXICON (LAYER)
create iac_layer word_level
word_level represent (vocab column_rep Word)

# LEXICAL ROUTE CONNECTIONS

# ## FEATURE-LETTER
create connection flc
flc autoconnect feature_level letter_level

#create parallel_conversion lfpc
#lfpc set_source letter_rep
#lfpc set_target feat_rep

# ## LETTER-ORTH
create string_split orth_str
# string_split is a conversion; it is a special conversion that generates the target representation
#   this target representation is (orth_str target)
#   (orth_str target) is a block_rep of (orth_str inner)
#   (orth_str inner) is a string_representation that is the single letters used in
#      (vocab column_rep Word string_representation)
orth_str set_blank "
orth_str set_source (vocab column_rep Word string_representation)
#   (vocab column_rep Word) == (vocab column_rep Word keyed_representation) which is a keyed_representation
#   (vocab column_rep Word string_representation) is the "dog" string_rep rather than the binary keyed_rep



create equiv_conversion letters
letters set_target (features_db column_rep letter string_representation)
letters set_source (orth_str inner)

create equiv_conversion letters2
letters2 set_source (features_db column_rep letter string_representation)
letters2 set_target (orth_str inner)


# this section is to ensure that we can use our special non-letter letters (ambiguous R/K stimulus: *)
((features_db column_rep features) find_conversion (orth_str inner)) set_auto 1
create parallel_conversion bananas
bananas set_source (orth_str get_target)
bananas set_target feat_rep

# these are the old solution to the problem of ensuring we can map from the string_rep to the feature
#    binary patterns; I suspect unnecessary with the above [UPDATE: CD -- tested script without the following, and conversions failed]
create parallel_conversion lopc
lopc set_source letter_rep
lopc set_target (orth_str get_target)
create parallel_conversion lopc2
lopc2 set_source (orth_str get_target)
lopc2 set_target letter_rep

lopc2 description

#((features_db column_rep letter keyed_representation) find_conversion (orth_str inner))
letters2
letters


#loglevel debug
create connection loc
loc autoconnect letter_level word_level

#loc details

create connection olc
word_level
letter_level
olc autoconnect word_level letter_level


# ## ORTH-ORTH
create connection lato
lato autoconnect word_level word_level

#create connection leto
#leto autoconnect letter_level letter_level

# OBSERVERS

create above_threshold_observer lexical_decider
lexical_decider target word_level
iam define_output lexical_decision lexical_decider

# MODEL GROUP
#create model iam

#iam add feature_level letter_level flc word_level loc olc lato 

xml iam description

(iam parameters) load Databases/Parameter_Sets/IA/ia.eNp

loc parameter_info
word_level parameter_info


word_level set_resting_level (vocab column_rep Rest)

create pattern rk_letter
rk_letter set (orth_str inner) *

create pattern rk_feats
rk_feats set (features_db column_rep features) 2P 3A 4A 7P 9P 10A 11A 12P 13A 14A

create pattern mask_letter
mask_letter set (orth_str inner) #

create pattern mask_feats
mask_feats set (features_db column_rep features) 1P 2P 3P 4A 5P 6P 7A 8A 9P 10P 11A 12P 13P 14P

create pattern blank_letter
blank_letter set (orth_str inner) _ 

create pattern blank_feats
blank_feats set (features_db column_rep features)

create pattern space_letter
space_letter set (orth_str inner) "

create pattern space_feats 1A 2A 3A 4A 5A 6A 7A 8A 9A 10A 11A 12A 13A 14A
space_feats set (features_db column_rep features)


create manual_conversion extras
extras set_auto_use 0
extras set_source (orth_str inner)
extras set_target (features_db column_rep features)
extras add rk_letter rk_feats
extras add mask_letter mask_feats
extras add blank_letter blank_feats
extras add space_letter space_feats


((features_db column_rep features) find_conversion (orth_str inner)) add_fallback extras
((features_db column_rep features) find_conversion (orth_str inner)) set_weight -1


create pattern _mask
_mask set (vocab column_rep Word string_representation) ####
#feat_rep 1P/0 2P/0 3P/0 4A/0 5P/0 6P/0  7A/0 8A/0 9P/0 10P/0 11A/0 12P/0 13P/0 14P/0 1P/1 2P/1 3P/1 4A/1 5P/1 6P/1 7A/1 8A/1 9P/1 10P/1 11A/1 12P/1 13P/1 14P/1 1P/2 2P/2 3P/2 4A/2 5P/2 6P/2 7A/2 8A/2 9P/2 10P/2 11A/2 12P/2 13P/2 14P/2 1P/3 2P/3 3P/3 4A/3 5P/3 6P/3 7A/3 8A/3 9P/3 10P/3 11A/3 12P/3 13P/3 14P/3

create pattern blank

create pattern spaces
spaces set (vocab column_rep Word string_representation) """"

#create dataframe output

#create dflog_nobserver nobs
#nobs add_trigger (word_level state)
#nobs add_pattern (word_level state)

(word_level default_observer) enable

create trial brief_masked
brief_masked add_stimulus_event stimulus orthographic START +$duration $stimulus
brief_masked add_stimulus_event mask orthographic stimulus/end +25 ####
brief_masked set_end_condition mask/end

brief_masked set_cap 50

#loglevel debug

set duration=15
set stimulus=mave
brief_masked step 
unset stimulus

#R << print((eN["output"])[1:5,1:5])
#R << print(str(eN["output"]))
#R << print(rownames(eN["output"]))
#R << write.csv(x=eN["(nobs default_dataframe)"],file="test.csv")

create rplot plo


plo set_type activity.R
xml plo list_settings
plo setting_object df ((word_level default_observer) get_dataframe)
plo setting threshold .05
plo setting max_n_units 8
plo setting prefer c("move","word")
xml plo list_settings
plo lsave_as test.svg

(word_level default_observer) disable
create stimulus_set andrews
andrews load Databases/Stimulus_files/Andrews_92_short.eNd

#R << print(colnames(eN["output"]))
create trial ldt
ldt add_stimulus_event stimulus orthographic START END $stimulus
ldt set_end_condition lexical_decision
ldt set_cap 100

andrews run_trials ldt
R << write.csv(x=eN["((ldt default_observer) default_dataframe)"],file="test.csv")

create rplot plo2
plo2 set_type mean_bars.R
plo2 setting_object df ((ldt default_observer) get_dataframe)
plo2 list_settings
plo2 setting_object aux andrews
plo2 setting key "(ldt event_pattern stimulus)"
plo2 setting key.aux "stimulus"
plo2 setting y "(ldt response_time lexical_decision)"
plo2 setting classify.aux c("Frequency","N")
xmllint 1
xml plo2 list_settings
xml plo2 get_setting_levels key.aux

plo2 lsave_as test2.svg
plo lsave_as test3.svg

#plo2 set_type activity.R
#xml plo2 list_settings

